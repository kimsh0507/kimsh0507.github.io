---
---

@misc{kim2024evaluatingrobustnessrewardmodels,
      title={Evaluating Robustness of Reward Models for Mathematical Reasoning}, 
      author={Sunghwan Kim† and Dongjin Kang† and Taeyoon Kwon and Hyungjoo Chae and Jungsoo Won and Dongha Lee and Jinyoung Yeo},
      year={2024},
      eprint={2410.01729},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2410.01729}, 
      selected={true},
      arxiv={2410.01729},
      code={https://github.com/kimsh0507/RewardMATH_official},
      preview={RewardMATH.png},
      abbr={Reward Model},
}

@inproceedings{lee2024cactuspsychologicalcounselingconversations,
      title={Cactus: Towards Psychological Counseling Conversations using Cognitive Behavioral Theory}, 
      author={Suyeon Lee† and Sunghwan Kim† and Minju Kim† and Dongjin Kang and Dongil Yang and Harim Kim and Minseok Kang and Dayi Jung and Min Hee Kim and Seungbeen Lee and Kyoung-Mee Chung and Youngjae Yu and Dongha Lee and Jinyoung Yeo},
      year={2024},
      eprint={2407.03103},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2407.03103}, 
      booktitle = "EMNLP 2024 findings",
      selected={true},
      arxiv={2404.02575},
      preview={Cactus.png},
      abbr={Dialogue},
}

@inproceedings{chae2024languagemodelscompilerssimulating,
      title={Language Models as Compilers: Simulating Pseudocode Execution Improves Algorithmic Reasoning in Language Models}, 
      author={Hyungjoo Chae and Yeonghyeon Kim and Seungone Kim and Kai Tzu-iunn Ong and Beong-woo Kwak and Moohyeon Kim and Seonghwan Kim and Taeyoon Kwon and Jiwan Chung and Youngjae Yu and Jinyoung Yeo},
      year={2024},
      eprint={2404.02575},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2404.02575}, 
      booktitle = "EMNLP 2024",
      selected={true},
      arxiv={2407.03103},
      code={https://github.com/coding-groot/cactus},
      preview={Think_Execute.png},
      abbr={Reasoning},
}

@inproceedings{kang-etal-2024-large,
    title = "Can Large Language Models be Good Emotional Supporter? Mitigating Preference Bias on Emotional Support Conversation",
    author = "Kang†, Dongjin  and
      Kim†, Sunghwan and
      Kwon, Taeyoon  and
      Moon, Seungjun  and
      Cho, Hyunsouk  and
      Yu, Youngjae  and
      Lee, Dongha  and
      Yeo, Jinyoung",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.acl-long.813",
    doi = "10.18653/v1/2024.acl-long.813",
    pages = "15232--15261",
    abstract = "Emotional Support Conversation (ESC) is a task aimed at alleviating individuals{'} emotional distress through daily conversation. Given its inherent complexity and non-intuitive nature, ESConv dataset incorporates support strategies to facilitate the generation of appropriate responses. Recently, despite the remarkable conversational ability of large language models (LLMs), previous studies have suggested that they often struggle with providing useful emotional support. Hence, this work initially analyzes the results of LLMs on ESConv, revealing challenges in selecting the correct strategy and a notable preference for a specific strategy. Motivated by these, we explore the impact of the inherent preference in LLMs on providing emotional support, and consequently, we observe that exhibiting high preference for specific strategies hinders effective emotional support, aggravating its robustness in predicting the appropriate strategy. Moreover, we conduct a methodological study to offer insights into the necessary approaches for LLMs to serve as proficient emotional supporters. Our findings emphasize that (1) low preference for specific strategies hinders the progress of emotional support, (2) external assistance helps reduce preference bias, and (3) existing LLMs alone cannot become good emotional supporters. These insights suggest promising avenues for future research to enhance the emotional intelligence of LLMs.",
    booktitle = "ACL 2024",
    selected={true},
    arxiv={2402.13211},
    award={Outstanding Paper Award},
    preview={ESC.png},
    abbr={Dialogue},
}
